services:
  hadoop-namenode:
    build:
      context: ./hadoop/namenode
    container_name: hadoop-namenode
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - JAVA_HOME=/usr/lib/jvm/jre/
    ports:
      - "9870:9870" # NameNode Web UI
      - "9000:9000" # NameNode RPC
    networks:
      - bigdata_network

  hadoop-datanode:
    build:
      context: ./hadoop/datanode
    container_name: hadoop-datanode
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - JAVA_HOME=/usr/lib/jvm/jre/
    depends_on:
      - hadoop-namenode
    networks:
      - bigdata_network

  spark-master:
    image: spark-hadoop-client:3.4.1
    container_name: spark-master
    user: root
    command: >
      /bin/bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - JAVA_HOME=/opt/java/openjdk
    ports:
      - "8080:8080"
      - "7077:7077"
    networks:
      - bigdata_network

  spark-worker:
    image: spark-hadoop-client:3.4.1
    container_name: spark-worker
    user: root
    command: >
      /bin/bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
    environment:
      - SPARK_WORKER_HOST=spark-worker
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - JAVA_HOME=/opt/java/openjdk
    ports:
      - "8081:8081"
    depends_on:
      - spark-master
    networks:
      - bigdata_network

  nifi:
    image: nifi-hadoop:1.21.0
    container_name: nifi
    user: root
    environment:
      - NIFI_WEB_HTTP_PORT=8084
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
    ports:
      - "8082:8084" # NiFi Web UI mapeado para localhost:8082
    volumes:
      - /c/fiap/volumes/nifi/data:/opt/nifi/nifi-current/data
      - /c/fiap/volumes/nifi/conf:/opt/nifi/nifi-current/conf      
    networks:
      - bigdata_network

  postgres:
    image: postgres:14
    container_name: postgres
    environment:
      - POSTGRES_USER=admin
      - POSTGRES_PASSWORD=fiapskyllsinc
      - POSTGRES_DB=datawarehouse
    volumes:
      - /c/fiap/docker/postgres/data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - bigdata_network

  jupyter:
    image: jupyter-hadoop-client:3.4.1
    container_name: jupyter
    volumes:
      - /c/fiap/docker/jupyter/notebooks:/home/jovyan/work
    ports:
      - "8888:8888"
    environment:
      - PYSPARK_SUBMIT_ARGS=--master spark://spark-master:7077 pyspark-shell
      - HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
      - CLASSPATH=/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/share/hadoop/yarn/*:/usr/local/hadoop/share/hadoop/tools/lib/*
      - LD_LIBRARY_PATH=/usr/local/hadoop/lib/native     
    depends_on:
      - spark-master
    networks:
      - bigdata_network

networks:
  bigdata_network:
    driver: bridge
